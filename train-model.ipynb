{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zlb7jFEQcAZf","executionInfo":{"status":"ok","timestamp":1745318286332,"user_tz":-180,"elapsed":21250,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"02fe284e-bef0-436a-9ab3-c1bdcb17108b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/DI725/DI725-assignment2\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/DI725/DI725-assignment2/"]},{"cell_type":"markdown","metadata":{"id":"06-VGDHXc6cd"},"source":["We will be working with the [AU-AIR dataset](https://bozcani.github.io/auairdataset), which consists of around 30k annotated low altitute traffic surveillance images with 8 object categories."]},{"cell_type":"code","source":["import os\n","import json\n","import torch\n","import numpy as np\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import YolosForObjectDetection, YolosConfig, YolosImageProcessor\n","from transformers import Trainer, TrainingArguments\n","from transformers.integrations import TensorBoardCallback, WandbCallback\n","from transformers.trainer_callback import EarlyStoppingCallback\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from tqdm import tqdm\n","import random\n","import wandb\n","import datetime\n","import pickle\n","\n","\n","# Configuration\n","DATA_DIR = \"auair2019data\"\n","IMAGES_DIR = os.path.join(DATA_DIR, \"images\")\n","ANNOTATIONS_FILE = os.path.join(DATA_DIR, \"annotations.json\")\n","OUTPUT_DIR = \"yolos_finetuned\"\n","MODEL_CHECKPOINT = \"hustvl/yolos-small\"\n","BATCH_SIZE = 4  # Smaller batch size to accommodate more images\n","LEARNING_RATE = 3e-5\n","NUM_EPOCHS = 20  # More epochs for large dataset\n","WARMUP_RATIO = 0.05  # Warmup ratio instead of fixed steps for large dataset\n","GRAD_ACCUMULATION_STEPS = 16  # for effective batch size of 64\n","NUM_WORKERS = 8  # For data loading\n","EVAL_STEPS = 200\n","SAVE_STEPS = 2000\n","EARLY_STOPPING_PATIENCE = 4  # Stop if no improvement for 4 evaluations\n","\n","# Wandb configuration\n","WANDB_PROJECT = \"object_detection_transformer\"\n","WANDB_NAME = f\"yolos-small-{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n","\n","\n","# Seed everything for reproducibility\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything()\n","\n","# Initialize wandb\n","print(\"Initializing wandb...\")\n","wandb.init(\n","    project=WANDB_PROJECT,\n","    name=WANDB_NAME,\n","    config={\n","        \"model_checkpoint\": MODEL_CHECKPOINT,\n","        \"batch_size\": BATCH_SIZE,\n","        \"learning_rate\": LEARNING_RATE,\n","        \"epochs\": NUM_EPOCHS,\n","        \"warmup_ratio\": WARMUP_RATIO,\n","        \"grad_accumulation_steps\": GRAD_ACCUMULATION_STEPS,\n","        \"effective_batch_size\": BATCH_SIZE * GRAD_ACCUMULATION_STEPS,\n","        \"early_stopping_patience\": EARLY_STOPPING_PATIENCE,\n","    }\n",")\n","\n","# Load annotations\n","print(\"Loading annotations...\")\n","with open(ANNOTATIONS_FILE, 'r') as f:\n","    data = json.load(f)\n","\n","# Extract category information\n","categories = {idx: cat for idx, cat in enumerate(data['categories'], start=0)}\n","id2label = {k: v for k, v in categories.items()}\n","label2id = {v: k for k, v in id2label.items()}\n","num_labels = len(id2label)\n","\n","print(f\"Found {num_labels} categories: {id2label}\")\n","wandb.config.update({\"num_classes\": num_labels, \"classes\": list(id2label.values())})\n","\n","annotations = data[\"annotations\"]\n","\n","# class distribution\n","category_counts = {class_name: 0 for class_name in id2label.values()}\n","for image_data in annotations:\n","    if \"bbox\" in image_data:\n","        for bbox in image_data[\"bbox\"]:\n","            class_id = bbox[\"class\"]\n","            if class_id in id2label:\n","                category_counts[id2label[class_id]] += 1\n","\n","#wandb.log({\"class_distribution\": wandb.Table(\n","#    columns=[\"Category\", \"Count\"],\n","#    data=[[cat, count] for cat, count in category_counts.items()]\n","#)})\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"LjgKlDXXn2-S","executionInfo":{"status":"ok","timestamp":1745318329653,"user_tz":-180,"elapsed":40160,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"be5ead75-ebb8-4fc9-ba68-0b3af11a6766"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing wandb...\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myildizz-nisan\u001b[0m (\u001b[33myildizz-nisan-middle-east-technical-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/DI725/DI725-assignment2/wandb/run-20250422_103846-6llyr0xf</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/6llyr0xf' target=\"_blank\">yolos-small-20250422-103829</a></strong> to <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer' target=\"_blank\">https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/6llyr0xf' target=\"_blank\">https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/6llyr0xf</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loading annotations...\n","Found 8 categories: {0: 'Human', 1: 'Car', 2: 'Truck', 3: 'Van', 4: 'Motorbike', 5: 'Bicycle', 6: 'Bus', 7: 'Trailer'}\n"]}]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","\n","class CustomObjectDetectionDataset(Dataset):\n","    def __init__(self, annotations, img_dir, processor, transform=None):\n","        self.annotations = annotations\n","        self.img_dir = img_dir\n","        self.processor = processor\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, idx):\n","        # Load annotation\n","        ann_data = self.annotations[idx]\n","        img_path = os.path.join(self.img_dir, ann_data[\"image_name\"])\n","\n","        image = Image.open(img_path)\n","\n","        image_width, image_height = image.size\n","\n","        # Prepare boxes & labels\n","        boxes = []\n","        labels = []\n","\n","        for bbox in ann_data[\"bbox\"]:\n","            x_min = bbox[\"left\"]\n","            y_min = bbox[\"top\"]\n","            width = bbox[\"width\"]\n","            height = bbox[\"height\"]\n","\n","            x_max = x_min + width\n","            y_max = y_min + height\n","\n","\n","            # Only add valid boxes (where max > min) before any transformations\n","            if x_max > x_min and y_max > y_min:\n","                boxes.append([x_min, y_min, width, height])\n","                labels.append(bbox[\"class\"])\n","\n","        boxes = np.array(boxes, dtype=np.float32) if boxes else np.zeros((0, 4), dtype=np.float32)\n","        labels = np.array(labels, dtype=np.int64) if labels else np.zeros((0,), dtype=np.int64)\n","\n","        # Albumentations transform\n","        if self.transform and len(boxes) > 0:\n","            try:\n","                transformed = self.transform(image=np.array(image), bboxes=boxes.tolist(), labels=labels.tolist())\n","                image = transformed['image']\n","                boxes = transformed['bboxes']\n","                labels = transformed['labels']\n","\n","                # Handle empty transform result\n","                if not boxes:\n","                    boxes = np.zeros((0, 4), dtype=np.float32)\n","                    labels = np.zeros((0,), dtype=np.int64)\n","                else:\n","                    boxes = np.array(boxes, dtype=np.float32)\n","                    labels = np.array(labels, dtype=np.int64)\n","\n","                    # Clip out-of-bounds\n","                    boxes = np.clip(boxes, 0.0, 1.0)\n","\n","                    # Filter out invalid boxes\n","                    valid_indices = []\n","                    for i, box in enumerate(boxes):\n","                        x_min, y_min, width, height = box\n","                        x_max = x_min + width\n","                        y_max = y_min + height\n","                        if x_max > x_min and y_max > y_min:\n","                            valid_indices.append(i)\n","\n","                    boxes = boxes[valid_indices] if valid_indices else np.zeros((0, 4), dtype=np.float32)\n","                    labels = labels[valid_indices] if valid_indices else np.zeros((0,), dtype=np.int64)\n","\n","            except Exception as e:\n","                print(f\"Error during transformation: {e}\")\n","                # Fall back to original image and empty boxes/labels\n","                image = np.array(image)\n","                boxes = np.zeros((0, 4), dtype=np.float32)\n","                labels = np.zeros((0,), dtype=np.int64)\n","        elif self.transform:\n","            # If there are no boxes but we have a transform\n","            image = self.transform(image=np.array(image))['image']\n","\n","        # Construct annotations for processor\n","        annotations = []\n","        for i, (box, label) in enumerate(zip(boxes, labels)):\n","            x_min, y_min, width, height = box\n","\n","            area = (width) * (height)\n","            annotations.append({\n","                'bbox': [x_min, y_min, width, height],\n","                'category_id': int(label),\n","                'area': float(area),\n","                'iscrowd': 0\n","            })\n","\n","        # Feed image + annotations into YOLOS processor\n","        encoding = self.processor(\n","            images=image,\n","            annotations={\n","                'image_id': idx,\n","                'annotations': annotations\n","            },\n","            return_tensors=\"pt\"\n","        )\n","\n","        # Remove batch dimension\n","        for k, v in encoding.items():\n","            if isinstance(v, torch.Tensor):\n","                encoding[k] = v.squeeze(0)  # remove batch dim only\n","            else:\n","                encoding[k] = v  # leave non-tensor items as-is\n","\n","        return encoding\n","\n","\n","def collate_fn(batch):\n","    batch_dict = {\n","        \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in batch])\n","    }\n","\n","    # For YOLOS, we need to keep labels as a list of label dictionaries\n","    if \"labels\" in batch[0]:\n","        batch_dict[\"labels\"] = [item[\"labels\"][0] for item in batch]\n","\n","    return batch_dict"],"metadata":{"id":"D52a7FnEuJRN","executionInfo":{"status":"ok","timestamp":1745318331165,"user_tz":-180,"elapsed":8,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","# Initialize image processor\n","print(f\"Loading YOLOS image processor from {MODEL_CHECKPOINT}\")\n","processor = YolosImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n","\n","# Define data augmentations\n","\n","train_transform = A.Compose(\n","    [\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.2),\n","        A.ShiftScaleRotate(\n","            shift_limit=0.05, scale_limit=0.1, rotate_limit=10, border_mode=0, p=0.5\n","        ),\n","    ],\n","    bbox_params=A.BboxParams(\n","        format='coco',\n","        label_fields=['labels'],\n","        min_visibility=0.1,         # Discard boxes too small or barely visible\n","        clip=True,            # clips bboxes to [0, 1]\n","    )\n",")\n","\n","val_transform = A.Compose(\n","    [],\n","    bbox_params=A.BboxParams(\n","        format='coco',\n","        label_fields=['labels'],\n","        clip=True,\n","    )\n",")\n","\n","\n","# Log augmentation pipeline to wandb\n","wandb.config.update({\n","    \"augmentations\": str(train_transform),\n","})\n","\n","# Create dataset\n","print(\"Creating datasets...\")\n","full_dataset = CustomObjectDetectionDataset(\n","    annotations,\n","    IMAGES_DIR,\n","    processor\n",")\n","\n","# If we haven't already split the dataset:\n","if not os.path.exists(f\"{OUTPUT_DIR}/dataset_splits.pkl\"):\n","\n","    # subsetting the data because it is too big\n","    subset_size = int(len(full_dataset) * 0.3)\n","\n","    # Create random subset indices\n","    indices = torch.randperm(len(full_dataset))[:subset_size]\n","\n","    # Create subset\n","    subset_dataset = torch.utils.data.Subset(full_dataset, indices)\n","\n","    # Split dataset\n","    train_size = int(0.7 * len(subset_dataset))\n","    remaining = len(subset_dataset) - train_size\n","    val_size = remaining // 2      # 15% of subset\n","    test_size = remaining - val_size  # 15% of subset\n","    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(subset_dataset, [train_size, val_size, test_size])\n","\n","    # Save splits using indices for reproducibility\n","    split_indices = {\n","        \"subset_indices\": indices,\n","        \"train_indices\": train_dataset.indices,\n","        \"val_indices\": val_dataset.indices,\n","        \"test_indices\": test_dataset.indices\n","    }\n","\n","    with open(f\"{OUTPUT_DIR}/dataset_splits.pkl\", \"wb\") as f:\n","        pickle.dump(split_indices, f)\n","\n","with open(f\"{OUTPUT_DIR}/dataset_splits.pkl\", \"rb\") as f:\n","    loaded_splits = pickle.load(f)\n","\n","#subset the data\n","subset_dataset = torch.utils.data.Subset(full_dataset, loaded_splits[\"subset_indices\"])\n","\n","# Recreate datasets using original dataset\n","train_dataset = torch.utils.data.Subset(subset_dataset, loaded_splits[\"train_indices\"])\n","val_dataset = torch.utils.data.Subset(subset_dataset, loaded_splits[\"val_indices\"])\n","test_dataset = torch.utils.data.Subset(subset_dataset, loaded_splits[\"test_indices\"])\n","\n","\n","# Apply transforms\n","train_dataset.dataset.transform = train_transform\n","val_dataset.dataset.transform = val_transform\n","test_dataset.dataset.transform = val_transform\n","\n","print(f\"Train dataset size: {len(train_dataset)}\")\n","print(f\"Validation dataset size: {len(val_dataset)}\")\n","print(f\"Test dataset size: {len(test_dataset)}\")\n","\n","\n","# Log data split info\n","wandb.config.update({\n","    \"train_size\": len(train_dataset),\n","    \"val_size\": len(val_dataset),\n","    \"train_val_ratio\": len(train_dataset) / len(val_dataset) if len(val_dataset) > 0 else \"N/A\",\n","})\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337,"referenced_widgets":["bc55e8086c3d4ebbacb2a6c8598f6c1c","27eb5c3e9ce141d4b30bd6ff0e44f5fb","57a4f6e1e58a4d609a20c4e9121e6ea2","8a7a7b675e49411bbd4ce0354ed4be3c","0777bcf69101493da68132704dd9cf0f","78668acaa6ce47639f2c7c06322b82fd","567eddc7c2494ccc8ba035a77e970467","850fde438b0d44f293c5ea038be9bf12","f505c9a0e94c48989567ced6f5d9e38e","abdff25b82ab4c76a6b6916a6119c901","b468e64e7f4d4ceca0cae7b2d2355334"]},"id":"9SiURuxLwU6G","executionInfo":{"status":"ok","timestamp":1745318337439,"user_tz":-180,"elapsed":1106,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"e7ae23e2-e65b-4703-a4bf-6337fe34307b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading YOLOS image processor from hustvl/yolos-small\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/292 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc55e8086c3d4ebbacb2a6c8598f6c1c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n","  original_init(self, **validated_kwargs)\n","/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py:250: UserWarning: Got processor for bboxes, but no transform to process it.\n","  self._set_keys()\n"]},{"output_type":"stream","name":"stdout","text":["Creating datasets...\n","Train dataset size: 6892\n","Validation dataset size: 1477\n","Test dataset size: 1477\n"]}]},{"cell_type":"markdown","source":["## Fine-tuning the YOLOS-small model"],"metadata":{"id":"m4qObLNVqiOz"}},{"cell_type":"code","source":["from transformers import TrainerCallback\n","\n","\n","# Get model with updated config for your number of classes\n","print(f\"Loading YOLOS model from {MODEL_CHECKPOINT}\")\n","config = YolosConfig.from_pretrained(MODEL_CHECKPOINT, id2label=id2label, label2id=label2id)\n","model = YolosForObjectDetection.from_pretrained(MODEL_CHECKPOINT, config=config, ignore_mismatched_sizes=True)\n","\n","# Log model architecture summary to wandb\n","wandb.config.update({\n","    \"model_params\": sum(p.numel() for p in model.parameters()),\n","    \"trainable_params\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n","})\n","\n","# Enable gradient checkpointing to save memory\n","model.gradient_checkpointing_enable()\n","\n","# Create a custom callback to log losses to wandb and print progress\n","class WandbLoggingCallback(TrainerCallback):\n","    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n","        if metrics is not None:\n","            # Calculate epoch from global step\n","            epoch = state.epoch\n","\n","            # Print evaluation information\n","            print(f\"\\n=== Evaluation at Step {state.global_step} (Epoch {epoch:.2f}) ===\")\n","            for key, value in metrics.items():\n","                if key != \"epoch\":\n","                    print(f\"Eval {key}: {value:.5f}\")\n","\n","            # Log eval metrics to wandb\n","            wandb.log(\n","                {f\"eval/{k}\": v for k, v in metrics.items() if k != \"epoch\"},\n","                step=state.global_step\n","            )\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        # Log training metrics\n","        if logs is not None:\n","            # Print training information\n","            if \"loss\" in logs:\n","                print(f\"Step {state.global_step} (Epoch {logs.get('epoch', state.epoch):.2f}) - Training loss: {logs['loss']:.5f}\")\n","\n","            # Filter out eval metrics which are handled in on_evaluate\n","            train_logs = {k: v for k, v in logs.items() if not k.startswith(\"eval_\")}\n","            wandb.log(\n","                {f\"train/{k}\": v for k, v in train_logs.items() if k != \"epoch\"},\n","                step=state.global_step\n","            )\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    learning_rate=LEARNING_RATE,\n","    num_train_epochs=NUM_EPOCHS,\n","    warmup_ratio=WARMUP_RATIO,\n","    weight_decay=0.01,\n","    eval_strategy=\"steps\",\n","    eval_steps=EVAL_STEPS,\n","    save_strategy=\"steps\",\n","    save_steps=SAVE_STEPS,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    greater_is_better=False,\n","    push_to_hub=False,\n","    fp16=True,\n","    gradient_accumulation_steps=GRAD_ACCUMULATION_STEPS,\n","    save_total_limit=3,\n","    dataloader_num_workers=NUM_WORKERS,\n","    dataloader_drop_last=True,\n","    dataloader_pin_memory=True,\n","    report_to=\"wandb\",\n","    gradient_checkpointing=True,\n","    ddp_find_unused_parameters=False,\n","    logging_strategy=\"steps\",  # Log at the same frequency as evaluation\n","    logging_steps=EVAL_STEPS // 5,  # Log more frequently than evaluation for better tracking\n","    logging_first_step=True,  # Log the first step to get initial loss\n",")\n","\n","# Initialize Trainer with early stopping and wandb logging\n","print(\"Initializing the Trainer...\")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=collate_fn,\n","    callbacks=[\n","        EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE),\n","        WandbLoggingCallback(),  # Add custom wandb logging callback\n","    ],\n",")\n","\n","# Train the model\n","print(\"\\n\" + \"=\"*50)\n","print(\"Starting training...\")\n","print(f\"Number of epochs: {NUM_EPOCHS}\")\n","print(f\"Training batch size: {BATCH_SIZE}\")\n","print(f\"Evaluation steps: Every {EVAL_STEPS} steps\")\n","print(f\"Saving steps: Every {SAVE_STEPS} steps\")\n","print(f\"Early stopping patience: {EARLY_STOPPING_PATIENCE} evaluations\")\n","print(\"=\"*50 + \"\\n\")\n","\n","train_result = trainer.train()\n","\n","# Print training summary\n","print(\"\\n\" + \"=\"*50)\n","print(\"Training completed!\")\n","print(f\"Total steps: {trainer.state.global_step}\")\n","print(f\"Final training loss: {train_result.training_loss:.5f}\")\n","print(\"=\"*50 + \"\\n\")\n","\n","# Save the final model\n","final_model_path = os.path.join(OUTPUT_DIR, \"final_model\")\n","trainer.save_model(final_model_path)\n","print(f\"Model saved to {final_model_path}\")\n","\n","# Create a validation dataset subset for final evaluation\n","print(\"\\nPerforming final evaluation...\")\n","eval_subset_size = min(1000, len(val_dataset))\n","eval_subset_indices = torch.randperm(len(val_dataset))[:eval_subset_size]\n","eval_subset = torch.utils.data.Subset(val_dataset, eval_subset_indices)\n","\n","# Evaluate the model on the validation subset\n","eval_results = trainer.evaluate(eval_dataset=eval_subset)\n","print(\"\\n\" + \"=\"*50)\n","print(\"Final evaluation results:\")\n","for key, value in eval_results.items():\n","    print(f\"{key}: {value:.5f}\")\n","print(\"=\"*50 + \"\\n\")\n","\n","# Finish wandb run\n","print(\"Finishing wandb run...\")\n","wandb.finish()\n","print(\"Training complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0a81b1d934ea425f9dee8cc9155187b4","23e0d7760bfe4bd19f931eb6d67b70f2","6111ff6fb5984e2c9891e906b5b69fb7","c51a760ff40b478c95a0dfbd693cf23f","f08049197ea44bb4a3a21a0cf8a85498","720dfad0734d4446a1f62d9a79681d65","d1e45d0b6de749b4948a47d6844943a0","d7296eed941f4f889c098caed8b67c41","e71e86dd6a604b2da8ce733ed76cb05c","f9b87a2af3db4b87acdd241c40d2f02f","96997d4a14314a6f908b6ddaaee4f54e","56258af453ce43008dc8d19efc0bc731","56b20aa3319f444eaae0d2840bbb98fa","8235e011f5e54bf280e0004b30b76efe","c708899fa9714d6186147dafc32e28dd","7b15deddb0794a14b6426d4044ade6ab","6260bc6d50814acb8fe74a407d507017","43f31a670e3f4228b85fab4272197604","d6b6e795d6a14564ad645ff8822e3df5","36d698d7f32f41eea264377479e4b621","e292bcd2b15e4dcd89359efde385aa05","e512eca547b443528468d9eb1f8a0f71"]},"id":"Uqz_Yt75CQmF","executionInfo":{"status":"ok","timestamp":1745313361800,"user_tz":-180,"elapsed":6618952,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"9862b789-86f3-4e84-c0f2-7c2e69f9b69c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading YOLOS model from hustvl/yolos-small\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/4.13k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a81b1d934ea425f9dee8cc9155187b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/123M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56258af453ce43008dc8d19efc0bc731"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of YolosForObjectDetection were not initialized from the model checkpoint at hustvl/yolos-small and are newly initialized because the shapes did not match:\n","- class_labels_classifier.layers.2.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([9]) in the model instantiated\n","- class_labels_classifier.layers.2.weight: found shape torch.Size([92, 384]) in the checkpoint and torch.Size([9, 384]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Initializing the Trainer...\n","\n","==================================================\n","Starting training...\n","Number of epochs: 20\n","Training batch size: 4\n","Evaluation steps: Every 200 steps\n","Saving steps: Every 2000 steps\n","Early stopping patience: 4 evaluations\n","==================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2140' max='2140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2140/2140 1:47:39, Epoch 19/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>1.561000</td>\n","      <td>1.563906</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.451300</td>\n","      <td>1.481082</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.411500</td>\n","      <td>1.470901</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.362500</td>\n","      <td>1.430606</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.319100</td>\n","      <td>1.401126</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>1.295600</td>\n","      <td>1.396470</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>1.295200</td>\n","      <td>1.380664</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>1.274900</td>\n","      <td>1.380914</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>1.259200</td>\n","      <td>1.371868</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.211500</td>\n","      <td>1.364194</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step 1 (Epoch 0.01) - Training loss: 3.70200\n","Step 40 (Epoch 0.37) - Training loss: 3.29850\n","Step 80 (Epoch 0.74) - Training loss: 2.07160\n","Step 120 (Epoch 1.11) - Training loss: 1.69690\n","Step 160 (Epoch 1.48) - Training loss: 1.59920\n","Step 200 (Epoch 1.85) - Training loss: 1.56100\n","\n","=== Evaluation at Step 200 (Epoch 1.85) ===\n","Eval eval_loss: 1.56391\n","Eval eval_runtime: 102.09700\n","Eval eval_samples_per_second: 14.46700\n","Eval eval_steps_per_second: 3.62400\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 240 (Epoch 2.22) - Training loss: 1.48300\n","Step 280 (Epoch 2.59) - Training loss: 1.50070\n","Step 320 (Epoch 2.97) - Training loss: 1.48460\n","Step 360 (Epoch 3.33) - Training loss: 1.43690\n","Step 400 (Epoch 3.71) - Training loss: 1.45130\n","\n","=== Evaluation at Step 400 (Epoch 3.71) ===\n","Eval eval_loss: 1.48108\n","Eval eval_runtime: 29.42700\n","Eval eval_samples_per_second: 50.19200\n","Eval eval_steps_per_second: 12.57300\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 440 (Epoch 4.07) - Training loss: 1.40470\n","Step 480 (Epoch 4.45) - Training loss: 1.40850\n","Step 520 (Epoch 4.82) - Training loss: 1.43060\n","Step 560 (Epoch 5.19) - Training loss: 1.39290\n","Step 600 (Epoch 5.56) - Training loss: 1.41150\n","\n","=== Evaluation at Step 600 (Epoch 5.56) ===\n","Eval eval_loss: 1.47090\n","Eval eval_runtime: 29.48000\n","Eval eval_samples_per_second: 50.10200\n","Eval eval_steps_per_second: 12.55100\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 640 (Epoch 5.93) - Training loss: 1.43230\n","Step 680 (Epoch 6.30) - Training loss: 1.34800\n","Step 720 (Epoch 6.67) - Training loss: 1.37660\n","Step 760 (Epoch 7.04) - Training loss: 1.37110\n","Step 800 (Epoch 7.41) - Training loss: 1.36250\n","\n","=== Evaluation at Step 800 (Epoch 7.41) ===\n","Eval eval_loss: 1.43061\n","Eval eval_runtime: 29.45300\n","Eval eval_samples_per_second: 50.14800\n","Eval eval_steps_per_second: 12.56200\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 840 (Epoch 7.78) - Training loss: 1.36000\n","Step 880 (Epoch 8.15) - Training loss: 1.32700\n","Step 920 (Epoch 8.52) - Training loss: 1.35130\n","Step 960 (Epoch 8.89) - Training loss: 1.34010\n","Step 1000 (Epoch 9.26) - Training loss: 1.31910\n","\n","=== Evaluation at Step 1000 (Epoch 9.26) ===\n","Eval eval_loss: 1.40113\n","Eval eval_runtime: 29.54950\n","Eval eval_samples_per_second: 49.98400\n","Eval eval_steps_per_second: 12.52100\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 1001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 1001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1040 (Epoch 9.63) - Training loss: 1.32050\n","Step 1080 (Epoch 10.00) - Training loss: 1.32350\n","Step 1120 (Epoch 10.37) - Training loss: 1.30920\n","Step 1160 (Epoch 10.74) - Training loss: 1.29990\n","Step 1200 (Epoch 11.11) - Training loss: 1.29560\n","\n","=== Evaluation at Step 1200 (Epoch 11.11) ===\n","Eval eval_loss: 1.39647\n","Eval eval_runtime: 29.57420\n","Eval eval_samples_per_second: 49.94200\n","Eval eval_steps_per_second: 12.51100\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 1201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 1201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1240 (Epoch 11.48) - Training loss: 1.28470\n","Step 1280 (Epoch 11.85) - Training loss: 1.28530\n","Step 1320 (Epoch 12.22) - Training loss: 1.28790\n","Step 1360 (Epoch 12.59) - Training loss: 1.28070\n","Step 1400 (Epoch 12.97) - Training loss: 1.29520\n","\n","=== Evaluation at Step 1400 (Epoch 12.97) ===\n","Eval eval_loss: 1.38066\n","Eval eval_runtime: 29.57510\n","Eval eval_samples_per_second: 49.94100\n","Eval eval_steps_per_second: 12.51100\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 1401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 1401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1440 (Epoch 13.33) - Training loss: 1.26710\n","Step 1480 (Epoch 13.71) - Training loss: 1.26660\n","Step 1520 (Epoch 14.07) - Training loss: 1.27330\n","Step 1560 (Epoch 14.45) - Training loss: 1.28180\n","Step 1600 (Epoch 14.82) - Training loss: 1.27490\n","\n","=== Evaluation at Step 1600 (Epoch 14.82) ===\n","Eval eval_loss: 1.38091\n","Eval eval_runtime: 29.65340\n","Eval eval_samples_per_second: 49.80900\n","Eval eval_steps_per_second: 12.47700\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 1601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 1601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1640 (Epoch 15.19) - Training loss: 1.22990\n","Step 1680 (Epoch 15.56) - Training loss: 1.25860\n","Step 1720 (Epoch 15.93) - Training loss: 1.25020\n","Step 1760 (Epoch 16.30) - Training loss: 1.23480\n","Step 1800 (Epoch 16.67) - Training loss: 1.25920\n","\n","=== Evaluation at Step 1800 (Epoch 16.67) ===\n","Eval eval_loss: 1.37187\n","Eval eval_runtime: 29.61300\n","Eval eval_samples_per_second: 49.87700\n","Eval eval_steps_per_second: 12.49400\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1800 that is less than the current step 1801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1800 that is less than the current step 1801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1840 (Epoch 17.04) - Training loss: 1.21550\n","Step 1880 (Epoch 17.41) - Training loss: 1.24720\n","Step 1920 (Epoch 17.78) - Training loss: 1.22770\n","Step 1960 (Epoch 18.15) - Training loss: 1.22340\n","Step 2000 (Epoch 18.52) - Training loss: 1.21150\n","\n","=== Evaluation at Step 2000 (Epoch 18.52) ===\n","Eval eval_loss: 1.36419\n","Eval eval_runtime: 29.60720\n","Eval eval_samples_per_second: 49.88700\n","Eval eval_steps_per_second: 12.49700\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2000 that is less than the current step 2001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2000 that is less than the current step 2001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 2040 (Epoch 18.89) - Training loss: 1.21830\n","Step 2080 (Epoch 19.26) - Training loss: 1.20570\n","Step 2120 (Epoch 19.63) - Training loss: 1.20610\n","\n","==================================================\n","Training completed!\n","Total steps: 2140\n","Final training loss: 1.38629\n","==================================================\n","\n","Model saved to yolos_finetuned/final_model\n","\n","Performing final evaluation...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/250 00:21]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 2140 (Epoch 19.82) ===\n","Eval eval_loss: 1.37559\n","Eval eval_runtime: 26.68600\n","Eval eval_samples_per_second: 37.47300\n","Eval eval_steps_per_second: 9.36800\n","\n","==================================================\n","Final evaluation results:\n","eval_loss: 1.37559\n","eval_runtime: 26.68600\n","eval_samples_per_second: 37.47300\n","eval_steps_per_second: 9.36800\n","epoch: 19.81718\n","==================================================\n","\n","Finishing wandb run...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▅▃▂▂▂▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█████████▆</td></tr><tr><td>eval/steps_per_second</td><td>▁█████████▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▇▃▂▃▃▂▂▂▂▂▄█▃▃▂▁▂▃▅▂▂▄▂▂▃▁▁▁▂▃▂▂▃▂▂▂▂▂▁▃</td></tr><tr><td>train/learning_rate</td><td>▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.37559</td></tr><tr><td>eval/runtime</td><td>26.686</td></tr><tr><td>eval/samples_per_second</td><td>37.473</td></tr><tr><td>eval/steps_per_second</td><td>9.368</td></tr><tr><td>total_flos</td><td>7.365561136055989e+19</td></tr><tr><td>train/epoch</td><td>19.81718</td></tr><tr><td>train/global_step</td><td>2140</td></tr><tr><td>train/grad_norm</td><td>22.06278</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2061</td></tr><tr><td>train/total_flos</td><td>7.365561136055989e+19</td></tr><tr><td>train/train_loss</td><td>1.38629</td></tr><tr><td>train/train_runtime</td><td>6580.1834</td></tr><tr><td>train/train_samples_per_second</td><td>20.948</td></tr><tr><td>train/train_steps_per_second</td><td>0.325</td></tr><tr><td>train_loss</td><td>1.38629</td></tr><tr><td>train_runtime</td><td>6580.1834</td></tr><tr><td>train_samples_per_second</td><td>20.948</td></tr><tr><td>train_steps_per_second</td><td>0.325</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolos-small-20250422-072449</strong> at: <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/35nuk3qv' target=\"_blank\">https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/35nuk3qv</a><br> View project at: <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer' target=\"_blank\">https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250422_072509-35nuk3qv/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tried to log to step 2140 that is less than the current step 2141. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tried to log to step 2140 that is less than the current step 2141. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete!\n"]}]},{"cell_type":"markdown","source":["## Inference and scores"],"metadata":{"id":"2na08g6_pghn"}},{"cell_type":"code","source":["MODEL_PATH = \"yolos_finetuned/final_model\"\n","model = YolosForObjectDetection.from_pretrained(MODEL_PATH).to(\"cuda\")\n"],"metadata":{"id":"y27s_HtIBGpA","executionInfo":{"status":"ok","timestamp":1745318464511,"user_tz":-180,"elapsed":279,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"0NcTZAUS690V","executionInfo":{"status":"ok","timestamp":1745317579558,"user_tz":-180,"elapsed":24,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#conf\n","IOU_THRESHOLD = 0.5\n","\n","#auair classes\n","CLASSES = ['Human','Car','Truck','Van','Motorbike','Bicycle','Bus','Trailer']\n","# colors for visualization\n","COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n","          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n","\n","\n","def plot_results(pil_img, prob, boxes):\n","    plt.figure(figsize=(16,10))\n","    plt.imshow(pil_img)\n","    ax = plt.gca()\n","    colors = COLORS * 100\n","    for p, (x_min, y_min, width, height), c in zip(prob, boxes.tolist(), colors):\n","        x_max = x_min + width\n","        y_max = y_min + height\n","        ax.add_patch(plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n","                                   fill=False, color=c, linewidth=3))\n","        cl = p.argmax()\n","        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n","        ax.text(x_min, y_min, text, fontsize=15,\n","                bbox=dict(facecolor='yellow', alpha=0.5))\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"CeRG69Bv5y6a","executionInfo":{"status":"ok","timestamp":1745318471285,"user_tz":-180,"elapsed":9,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# for output bounding box post-processing\n","\n","def box_xmymwh_to_xyxy(x):\n","    x_m, y_m, w, h = x.unbind(1)\n","    b = [x_m, y_m,\n","         (x_m + w), (y_m + h)]\n","    return torch.stack(b, dim=1).to('cuda')\n","\n","def auair_bbox_to_xyxy(bbox):\n","    x_min = bbox['left']\n","    y_min = bbox['top']\n","    x_max = x_min + bbox['width']\n","    y_max = y_min + bbox['height']\n","    return [x_min, y_min, x_max, y_max]\n","\n","def rescale_bboxes(out_bbox, size):\n","    img_w, img_h = size\n","    b = box_xmymwh_to_xyxy(out_bbox)\n","    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32).to('cuda')\n","    return b.to('cuda')"],"metadata":{"id":"50d3cj1T-lV5","executionInfo":{"status":"ok","timestamp":1745318473721,"user_tz":-180,"elapsed":34,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def calculate_iou(bbox1, bbox2):\n","    #bboxes are of form x_min, y_min, x_max, y_max\n","    x1 = max(bbox1[0], bbox2[0])\n","    y1 = max(bbox1[1], bbox2[1])\n","    x2 = min(bbox1[2], bbox2[2])\n","    y2 = min(bbox1[3], bbox2[3])\n","\n","    if x2 < x1 or y2 < y1:\n","        return 0\n","    intersection = (y2 - y1) * (x2 - x1)\n","    area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])\n","    area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])\n","    union = area1 + area2 - intersection\n","\n","    iou = intersection / union\n","    return iou\n","\n","\n","def find_closest_bbox(bbox, bboxes):\n","    max_iou = 0\n","    closest_bbox_index = None\n","    for i, bbox2 in enumerate(bboxes):\n","        iou = calculate_iou(bbox, bbox2)\n","        if iou > max_iou:\n","            max_iou = iou\n","            closest_bbox_index = i\n","    return closest_bbox_index, max_iou\n"],"metadata":{"id":"AuZ760TV__YE","executionInfo":{"status":"ok","timestamp":1745318475630,"user_tz":-180,"elapsed":6,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["test_annot = [annotations[i] for i in loaded_splits[\"test_indices\"]]"],"metadata":{"id":"cu74yTYt7tdP","executionInfo":{"status":"ok","timestamp":1745318478029,"user_tz":-180,"elapsed":6,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["test_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvidVI8AEIDW","executionInfo":{"status":"ok","timestamp":1745318479080,"user_tz":-180,"elapsed":31,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"04fc1599-1ffa-49f7-8818-845e7feff20d"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.dataset.Subset at 0x7c9a7cebf210>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","pipeline"],"metadata":{"id":"Cye0sKiqFpBG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_paths = []\n","test_outputs = []\n","test_ground_truth_bbox = []\n","test_ground_truth_classes = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for annot in tqdm(test_annot, desc=\"Evaluating samples\"):\n","        image_path = f'{IMAGES_DIR}/{annot[\"image_name\"]}'\n","        img = Image.open(image_path)\n","        image_paths.append(image_path)\n","\n","        # Process on GPU\n","        inputs = processor(images=img, return_tensors=\"pt\").to(\"cuda\")\n","        outputs = model(**inputs)\n","\n","        # Move to CPU before storing\n","        cpu_outputs = {k: v.detach().cpu() if isinstance(v, torch.Tensor) else v for k, v in outputs.items()}\n","        test_outputs.append(cpu_outputs)\n","\n","        ground_truth_bboxes = torch.Tensor([auair_bbox_to_xyxy(bbox) for bbox in annot['bbox']])  # Keep on CPU\n","        test_ground_truth_bbox.append(ground_truth_bboxes)\n","\n","        ground_truth_classes = torch.Tensor([bbox['class'] for bbox in annot['bbox']]).to(torch.int64)  # Keep on CPU\n","        test_ground_truth_classes.append(ground_truth_classes)\n","\n","        torch.cuda.empty_cache()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234},"id":"HTdeRrCB7q46","executionInfo":{"status":"error","timestamp":1745319419937,"user_tz":-180,"elapsed":553304,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"0e353ea0-986e-41d3-db0d-37a291aeff86"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating samples: 100%|██████████| 1477/1477 [09:13<00:00,  2.67it/s]\n"]},{"output_type":"error","ename":"KeyError","evalue":"'pred_logits'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-a4d3226b7d51>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# keep only predictions with 0.7+ confidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'pred_logits'"]}]},{"cell_type":"code","source":["for output in test_outputs:\n","\n","    # keep only predictions with 0.7+ confidence\n","    probas = output['logits'].softmax(-1)[0, :, :-1]\n","    keep = probas.max(-1).values > 0.7\n","\n","    # convert boxes from [0; 1] to image scales\n","    output['bboxes_scaled_filtered'] = rescale_bboxes(output['pred_boxes'][0, keep], img.size)\n","    output['probas_filtered'] = probas[keep]"],"metadata":{"id":"4BX5cKrhJeMD","executionInfo":{"status":"ok","timestamp":1745319488408,"user_tz":-180,"elapsed":559,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"0TcshUSADTET","executionInfo":{"status":"ok","timestamp":1745317874387,"user_tz":-180,"elapsed":6,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import math\n","\n","results = pd.DataFrame(columns=['image_name', 'true_class', 'pred_class', 'iou', 'pred_confidence'])\n","\n","for i in range(len(test_outputs)):\n","    image_path = image_paths[i]\n","    image_name = image_path.split('/')[-1]\n","    output = test_outputs[i]\n","    pred_probas = output['probas_filtered']\n","    pred_classes = [pred_probas[i].argmax() for i in range(len(pred_probas))]\n","    pred_bboxes = output['bboxes_scaled_filtered']\n","    ground_truth_bboxes = test_ground_truth_bbox[i]\n","    ground_truth_classes = [int(i) for i in test_ground_truth_classes[i]]\n","\n","    considered_ground_truth_indexes = []\n","    for j in range(len(pred_bboxes)):\n","        bbox = pred_bboxes[j]\n","        pred = pred_classes[j]\n","        closest_bbox_index, iou = find_closest_bbox(bbox, ground_truth_bboxes)\n","        considered_ground_truth_indexes.append(closest_bbox_index)\n","        if closest_bbox_index is None:\n","            result = {'image_name': image_name, 'true_class': math.nan,\n","                      'pred_class': int(pred),'iou': float(iou), 'pred_confidence': math.nan}\n","        else:\n","            result = {'image_name': image_name, 'true_class': ground_truth_classes[closest_bbox_index],\n","                  'pred_class': int(pred),'iou': float(iou), 'pred_confidence': float(pred_probas[j][pred])}\n","\n","        results = pd.concat([results, pd.DataFrame([result])], ignore_index=True)\n","    for i in range(len(ground_truth_bboxes)):\n","        if i not in considered_ground_truth_indexes:\n","            result = {'image_name': image_name, 'true_class': ground_truth_classes[i],\n","                      'pred_class': math.nan,'iou': math.nan, 'pred_confidence': math.nan}\n","            results = pd.concat([results, pd.DataFrame([result])], ignore_index=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxUxSbxTAdoz","executionInfo":{"status":"ok","timestamp":1745319681044,"user_tz":-180,"elapsed":7846,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"f5db9de5-cc66-417f-ff2b-7714087af73a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-55f10a4a718b>:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  results = pd.concat([results, pd.DataFrame([result])], ignore_index=True)\n"]}]},{"cell_type":"code","source":["results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"pnYa8pGbKO4U","executionInfo":{"status":"ok","timestamp":1745319688758,"user_tz":-180,"elapsed":89,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"c86a0096-6996-41de-f75e-7554d9065752"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                               image_name true_class pred_class       iou  \\\n","0      frame_20190905091750_x_0002490.jpg          1          1  0.162151   \n","1      frame_20190905091750_x_0002490.jpg          1          1  0.088314   \n","2      frame_20190905091750_x_0002490.jpg          1          1  0.149410   \n","3      frame_20190905091750_x_0002490.jpg          7          2  0.189316   \n","4      frame_20190905091750_x_0002490.jpg          1        NaN       NaN   \n","...                                   ...        ...        ...       ...   \n","5907  frame_20190905091750_xx_0001143.jpg          0          0  0.186102   \n","5908  frame_20190905091750_xx_0001143.jpg          1        NaN       NaN   \n","5909   frame_20190905091750_x_0004882.jpg          1          1  0.128156   \n","5910   frame_20190905091750_x_0004882.jpg          2        NaN       NaN   \n","5911   frame_20190905091750_x_0004882.jpg          2        NaN       NaN   \n","\n","      pred_confidence  \n","0            0.912359  \n","1            0.959211  \n","2            0.872258  \n","3            0.754010  \n","4                 NaN  \n","...               ...  \n","5907         0.768635  \n","5908              NaN  \n","5909         0.956187  \n","5910              NaN  \n","5911              NaN  \n","\n","[5912 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-b0945abb-f389-4440-b43b-f13f9c2456ba\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>true_class</th>\n","      <th>pred_class</th>\n","      <th>iou</th>\n","      <th>pred_confidence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>frame_20190905091750_x_0002490.jpg</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.162151</td>\n","      <td>0.912359</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>frame_20190905091750_x_0002490.jpg</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.088314</td>\n","      <td>0.959211</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>frame_20190905091750_x_0002490.jpg</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.149410</td>\n","      <td>0.872258</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>frame_20190905091750_x_0002490.jpg</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>0.189316</td>\n","      <td>0.754010</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>frame_20190905091750_x_0002490.jpg</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5907</th>\n","      <td>frame_20190905091750_xx_0001143.jpg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.186102</td>\n","      <td>0.768635</td>\n","    </tr>\n","    <tr>\n","      <th>5908</th>\n","      <td>frame_20190905091750_xx_0001143.jpg</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5909</th>\n","      <td>frame_20190905091750_x_0004882.jpg</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.128156</td>\n","      <td>0.956187</td>\n","    </tr>\n","    <tr>\n","      <th>5910</th>\n","      <td>frame_20190905091750_x_0004882.jpg</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5911</th>\n","      <td>frame_20190905091750_x_0004882.jpg</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5912 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0945abb-f389-4440-b43b-f13f9c2456ba')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b0945abb-f389-4440-b43b-f13f9c2456ba button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b0945abb-f389-4440-b43b-f13f9c2456ba');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1b995922-d752-4a68-ad38-edd6f6a67024\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b995922-d752-4a68-ad38-edd6f6a67024')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1b995922-d752-4a68-ad38-edd6f6a67024 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_4f6dcbc6-b2ea-4a55-bc82-9b0ae03e6c90\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_4f6dcbc6-b2ea-4a55-bc82-9b0ae03e6c90 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('results');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results","summary":"{\n  \"name\": \"results\",\n  \"rows\": 5912,\n  \"fields\": [\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1477,\n        \"samples\": [\n          \"frame_20190905091750_x_0004477.jpg\",\n          \"frame_20190905091750_x_0002322.jpg\",\n          \"frame_20190829091111_x_0001702.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_class\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_class\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iou\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07806412337401394,\n        \"min\": 0.0,\n        \"max\": 0.6744905710220337,\n        \"num_unique_values\": 3508,\n        \"samples\": [\n          0.048002324998378754,\n          0.1301223635673523,\n          0.09642313420772552\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08423553597103986,\n        \"min\": 0.700005054473877,\n        \"max\": 0.9866119623184204,\n        \"num_unique_values\": 3506,\n        \"samples\": [\n          0.9685342907905579,\n          0.917137861251831,\n          0.8173537850379944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["from sklearn.metrics import auc, average_precision_score\n","\n","def calculate_precision_recall(results, per_class = True, threshold = IOU_THRESHOLD):\n","    classes = results['true_class'].dropna().unique()\n","    TP = (results['true_class'] == results['pred_class']) & (results['iou'] >= threshold)\n","    FP = (results['iou'] < threshold) | (results['pred_class'] != results['true_class'])\n","    FN = (results['true_class'] != math.nan) & (results['pred_class'].isna())\n","    if per_class:\n","        precisions = []\n","        recalls = []\n","        for c in classes:\n","            tp = TP[results['true_class'] == c].sum()\n","            fp = FP[results['true_class'] == c].sum()\n","            fn = FN[results['true_class'] == c].sum()\n","\n","            precision = tp / (tp + fp)\n","            recall = tp / (tp + fn)\n","\n","            precisions.append(precision)\n","            recalls.append(recall)\n","        return precisions, recalls, classes\n","\n","    else:\n","        tp = TP.sum()\n","        fp = FP.sum()\n","        fn = FN.sum()\n","\n","        precision = tp / (tp + fp)\n","        recall = tp / (tp + fn)\n","        return precision, recall\n","\n","def calculate_map(results, per_class = True, threshold = IOU_THRESHOLD):\n","    if per_class:\n","        precisions_list_per_class = []\n","        recalls_list_per_class = []\n","        for threshold in np.arange(threshold,1,0.05):\n","            precisions, recalls, classes = calculate_precision_recall(results, per_class, threshold)\n","            precisions_list_per_class.append(precisions)\n","            recalls_list_per_class.append(recalls)\n","        map_per_class = []\n","        for i in range(len(classes)):\n","            precisions_list = []\n","            recalls_list = []\n","            for j in range(len(precisions_list_per_class)):\n","                precisions_list.append(precisions_list_per_class[j][i])\n","                recalls_list.append(recalls_list_per_class[j][i])\n","            map = round(auc(recalls_list, precisions_list),3)\n","            map_per_class.append(map)\n","        return map_per_class, classes\n","    else:\n","        precisions_list = []\n","        recalls_list = []\n","        for threshold in np.arange(threshold,1,0.05):\n","            precision, recall = calculate_precision_recall(results, per_class, threshold)\n","\n","            precisions_list.append(precision)\n","            recalls_list.append(recall)\n","\n","        map = round(auc(recalls_list, precisions_list),3)\n","\n","        return map\n","    classes = results['true_class'].dropna().unique()"],"metadata":{"id":"d-phcPYkAmC6","executionInfo":{"status":"ok","timestamp":1745319695722,"user_tz":-180,"elapsed":26,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["calculate_map(results, per_class = True, threshold = IOU_THRESHOLD)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S49xhQkiApn-","executionInfo":{"status":"ok","timestamp":1745319699847,"user_tz":-180,"elapsed":262,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"00f566c1-1251-49bc-e326-99c0059d4d3f"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([np.float64(0.0),\n","  np.float64(0.0),\n","  np.float64(0.0),\n","  np.float64(0.0),\n","  np.float64(0.0),\n","  np.float64(0.0),\n","  np.float64(0.0),\n","  np.float64(0.0)],\n"," array([1, 7, 2, 0, 6, 3, 5, 4], dtype=object))"]},"metadata":{},"execution_count":19}]}],"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyO0EoTeGNtWLD93448nSBnp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bc55e8086c3d4ebbacb2a6c8598f6c1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27eb5c3e9ce141d4b30bd6ff0e44f5fb","IPY_MODEL_57a4f6e1e58a4d609a20c4e9121e6ea2","IPY_MODEL_8a7a7b675e49411bbd4ce0354ed4be3c"],"layout":"IPY_MODEL_0777bcf69101493da68132704dd9cf0f"}},"27eb5c3e9ce141d4b30bd6ff0e44f5fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78668acaa6ce47639f2c7c06322b82fd","placeholder":"​","style":"IPY_MODEL_567eddc7c2494ccc8ba035a77e970467","value":"preprocessor_config.json: 100%"}},"57a4f6e1e58a4d609a20c4e9121e6ea2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_850fde438b0d44f293c5ea038be9bf12","max":292,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f505c9a0e94c48989567ced6f5d9e38e","value":292}},"8a7a7b675e49411bbd4ce0354ed4be3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abdff25b82ab4c76a6b6916a6119c901","placeholder":"​","style":"IPY_MODEL_b468e64e7f4d4ceca0cae7b2d2355334","value":" 292/292 [00:00&lt;00:00, 35.8kB/s]"}},"0777bcf69101493da68132704dd9cf0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78668acaa6ce47639f2c7c06322b82fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"567eddc7c2494ccc8ba035a77e970467":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"850fde438b0d44f293c5ea038be9bf12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f505c9a0e94c48989567ced6f5d9e38e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abdff25b82ab4c76a6b6916a6119c901":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b468e64e7f4d4ceca0cae7b2d2355334":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a81b1d934ea425f9dee8cc9155187b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23e0d7760bfe4bd19f931eb6d67b70f2","IPY_MODEL_6111ff6fb5984e2c9891e906b5b69fb7","IPY_MODEL_c51a760ff40b478c95a0dfbd693cf23f"],"layout":"IPY_MODEL_f08049197ea44bb4a3a21a0cf8a85498"}},"23e0d7760bfe4bd19f931eb6d67b70f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_720dfad0734d4446a1f62d9a79681d65","placeholder":"​","style":"IPY_MODEL_d1e45d0b6de749b4948a47d6844943a0","value":"config.json: 100%"}},"6111ff6fb5984e2c9891e906b5b69fb7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7296eed941f4f889c098caed8b67c41","max":4132,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e71e86dd6a604b2da8ce733ed76cb05c","value":4132}},"c51a760ff40b478c95a0dfbd693cf23f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9b87a2af3db4b87acdd241c40d2f02f","placeholder":"​","style":"IPY_MODEL_96997d4a14314a6f908b6ddaaee4f54e","value":" 4.13k/4.13k [00:00&lt;00:00, 374kB/s]"}},"f08049197ea44bb4a3a21a0cf8a85498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"720dfad0734d4446a1f62d9a79681d65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1e45d0b6de749b4948a47d6844943a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7296eed941f4f889c098caed8b67c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e71e86dd6a604b2da8ce733ed76cb05c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9b87a2af3db4b87acdd241c40d2f02f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96997d4a14314a6f908b6ddaaee4f54e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56258af453ce43008dc8d19efc0bc731":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56b20aa3319f444eaae0d2840bbb98fa","IPY_MODEL_8235e011f5e54bf280e0004b30b76efe","IPY_MODEL_c708899fa9714d6186147dafc32e28dd"],"layout":"IPY_MODEL_7b15deddb0794a14b6426d4044ade6ab"}},"56b20aa3319f444eaae0d2840bbb98fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6260bc6d50814acb8fe74a407d507017","placeholder":"​","style":"IPY_MODEL_43f31a670e3f4228b85fab4272197604","value":"model.safetensors: 100%"}},"8235e011f5e54bf280e0004b30b76efe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b6e795d6a14564ad645ff8822e3df5","max":122763274,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36d698d7f32f41eea264377479e4b621","value":122763274}},"c708899fa9714d6186147dafc32e28dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e292bcd2b15e4dcd89359efde385aa05","placeholder":"​","style":"IPY_MODEL_e512eca547b443528468d9eb1f8a0f71","value":" 123M/123M [00:00&lt;00:00, 225MB/s]"}},"7b15deddb0794a14b6426d4044ade6ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6260bc6d50814acb8fe74a407d507017":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43f31a670e3f4228b85fab4272197604":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6b6e795d6a14564ad645ff8822e3df5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36d698d7f32f41eea264377479e4b621":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e292bcd2b15e4dcd89359efde385aa05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e512eca547b443528468d9eb1f8a0f71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}