{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zlb7jFEQcAZf","executionInfo":{"status":"ok","timestamp":1745060276994,"user_tz":-180,"elapsed":27503,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"cf39aedc-a9e8-4b29-bc07-838ed808dac5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/DI725/DI725-assignment2\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/DI725/DI725-assignment2/"]},{"cell_type":"markdown","metadata":{"id":"06-VGDHXc6cd"},"source":["We will be working with the [AU-AIR dataset](https://bozcani.github.io/auairdataset), which consists of around 30k annotated low altitute traffic surveillance images with 8 object categories."]},{"cell_type":"code","source":["import os\n","import json\n","import torch\n","import numpy as np\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import YolosForObjectDetection, YolosConfig, YolosImageProcessor\n","from transformers import Trainer, TrainingArguments\n","from transformers.integrations import TensorBoardCallback, WandbCallback\n","from transformers.trainer_callback import EarlyStoppingCallback\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from tqdm import tqdm\n","import random\n","import wandb\n","import datetime\n","import pickle\n","\n","\n","# Configuration\n","DATA_DIR = \"auair2019data\"\n","IMAGES_DIR = os.path.join(DATA_DIR, \"images\")\n","ANNOTATIONS_FILE = os.path.join(DATA_DIR, \"annotations.json\")\n","OUTPUT_DIR = \"yolos_finetuned\"\n","MODEL_CHECKPOINT = \"hustvl/yolos-small\"\n","BATCH_SIZE = 4  # Smaller batch size to accommodate more images\n","LEARNING_RATE = 3e-5\n","NUM_EPOCHS = 20  # More epochs for large dataset\n","WARMUP_RATIO = 0.05  # Warmup ratio instead of fixed steps for large dataset\n","GRAD_ACCUMULATION_STEPS = 16  # for effective batch size of 64\n","NUM_WORKERS = 8  # For data loading\n","EVAL_STEPS = 200\n","SAVE_STEPS = 2000\n","EARLY_STOPPING_PATIENCE = 4  # Stop if no improvement for 4 evaluations\n","\n","# Wandb configuration\n","WANDB_PROJECT = \"object_detection_transformer\"\n","WANDB_NAME = f\"yolos-small-{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n","\n","\n","# Seed everything for reproducibility\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything()\n","\n","# Initialize wandb\n","print(\"Initializing wandb...\")\n","wandb.init(\n","    project=WANDB_PROJECT,\n","    name=WANDB_NAME,\n","    config={\n","        \"model_checkpoint\": MODEL_CHECKPOINT,\n","        \"batch_size\": BATCH_SIZE,\n","        \"learning_rate\": LEARNING_RATE,\n","        \"epochs\": NUM_EPOCHS,\n","        \"warmup_ratio\": WARMUP_RATIO,\n","        \"grad_accumulation_steps\": GRAD_ACCUMULATION_STEPS,\n","        \"effective_batch_size\": BATCH_SIZE * GRAD_ACCUMULATION_STEPS,\n","        \"early_stopping_patience\": EARLY_STOPPING_PATIENCE,\n","    }\n",")\n","\n","# Load annotations\n","print(\"Loading annotations...\")\n","with open(ANNOTATIONS_FILE, 'r') as f:\n","    data = json.load(f)\n","\n","# Extract category information\n","categories = {idx: cat for idx, cat in enumerate(data['categories'], start=0)}\n","id2label = {k: v for k, v in categories.items()}\n","label2id = {v: k for k, v in id2label.items()}\n","num_labels = len(id2label)\n","\n","print(f\"Found {num_labels} categories: {id2label}\")\n","wandb.config.update({\"num_classes\": num_labels, \"classes\": list(id2label.values())})\n","\n","annotations = data[\"annotations\"]\n","\n","# class distribution\n","category_counts = {class_name: 0 for class_name in id2label.values()}\n","for image_data in annotations:\n","    if \"bbox\" in image_data:\n","        for bbox in image_data[\"bbox\"]:\n","            class_id = bbox[\"class\"]\n","            if class_id in id2label:\n","                category_counts[id2label[class_id]] += 1\n","\n","wandb.log({\"class_distribution\": wandb.Table(\n","    columns=[\"Category\", \"Count\"],\n","    data=[[cat, count] for cat, count in category_counts.items()]\n",")})\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"LjgKlDXXn2-S","executionInfo":{"status":"ok","timestamp":1745060322689,"user_tz":-180,"elapsed":41648,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"4f45e800-3f4c-4efe-8521-246a856a112d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing wandb...\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myildizz-nisan\u001b[0m (\u001b[33myildizz-nisan-middle-east-technical-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/DI725/DI725-assignment2/wandb/run-20250419_105838-z6szt6dd</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/z6szt6dd' target=\"_blank\">yolos-small-20250419-105820</a></strong> to <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer' target=\"_blank\">https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/z6szt6dd' target=\"_blank\">https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/z6szt6dd</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loading annotations...\n","Found 8 categories: {0: 'Human', 1: 'Car', 2: 'Truck', 3: 'Van', 4: 'Motorbike', 5: 'Bicycle', 6: 'Bus', 7: 'Trailer'}\n"]}]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","\n","class CustomObjectDetectionDataset(Dataset):\n","    def __init__(self, annotations, img_dir, processor, transform=None):\n","        self.annotations = annotations\n","        self.img_dir = img_dir\n","        self.processor = processor\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, idx):\n","        # Load annotation\n","        ann_data = self.annotations[idx]\n","        img_path = os.path.join(self.img_dir, ann_data[\"image_name\"])\n","\n","        # Load image safely\n","        try:\n","            image = Image.open(img_path).convert(\"RGB\")\n","        except Exception as e:\n","            print(f\"Error loading image {img_path}: {e}\")\n","            image = Image.new('RGB', (640, 640), color='gray')\n","            ann_data[\"bbox\"] = []\n","\n","        image_width, image_height = image.size\n","\n","        # Prepare boxes & labels\n","        boxes = []\n","        labels = []\n","\n","        for bbox in ann_data[\"bbox\"]:\n","            x_min = bbox[\"left\"]\n","            y_min = bbox[\"top\"]\n","            width = bbox[\"width\"]\n","            height = bbox[\"height\"]\n","\n","            x_max = x_min + width\n","            y_max = y_min + height\n","\n","            # Normalize to [0, 1]\n","            x_min = max(0, x_min / image_width)\n","            y_min = max(0, y_min / image_height)\n","            x_max = min(1, x_max / image_width)\n","            y_max = min(1, y_max / image_height)\n","\n","            # Only add valid boxes (where max > min) before any transformations\n","            if x_max > x_min and y_max > y_min:\n","                boxes.append([x_min, y_min, x_max, y_max])\n","                labels.append(bbox[\"class\"])\n","\n","        boxes = np.array(boxes, dtype=np.float32) if boxes else np.zeros((0, 4), dtype=np.float32)\n","        labels = np.array(labels, dtype=np.int64) if labels else np.zeros((0,), dtype=np.int64)\n","\n","        # Albumentations transform\n","        if self.transform and len(boxes) > 0:\n","            try:\n","                transformed = self.transform(image=np.array(image), bboxes=boxes.tolist(), labels=labels.tolist())\n","                image = transformed['image']\n","                boxes = transformed['bboxes']\n","                labels = transformed['labels']\n","\n","                # Handle empty transform result\n","                if not boxes:\n","                    boxes = np.zeros((0, 4), dtype=np.float32)\n","                    labels = np.zeros((0,), dtype=np.int64)\n","                else:\n","                    boxes = np.array(boxes, dtype=np.float32)\n","                    labels = np.array(labels, dtype=np.int64)\n","\n","                    # Clip out-of-bounds\n","                    boxes = np.clip(boxes, 0.0, 1.0)\n","\n","                    # Filter out invalid boxes\n","                    valid_indices = []\n","                    for i, box in enumerate(boxes):\n","                        x_min, y_min, x_max, y_max = box\n","                        if x_max > x_min and y_max > y_min:\n","                            valid_indices.append(i)\n","\n","                    boxes = boxes[valid_indices] if valid_indices else np.zeros((0, 4), dtype=np.float32)\n","                    labels = labels[valid_indices] if valid_indices else np.zeros((0,), dtype=np.int64)\n","\n","            except Exception as e:\n","                print(f\"Error during transformation: {e}\")\n","                # Fall back to original image and empty boxes/labels\n","                image = np.array(image)\n","                boxes = np.zeros((0, 4), dtype=np.float32)\n","                labels = np.zeros((0,), dtype=np.int64)\n","        elif self.transform:\n","            # If there are no boxes but we have a transform\n","            image = self.transform(image=np.array(image))['image']\n","\n","        # Construct annotations for processor\n","        annotations = []\n","        for i, (box, label) in enumerate(zip(boxes, labels)):\n","            x_min, y_min, x_max, y_max = box\n","            # Double-check validity of box\n","            if x_max <= x_min or y_max <= y_min:\n","                continue\n","\n","            area = (x_max - x_min) * (y_max - y_min)\n","            annotations.append({\n","                'bbox': [x_min, y_min, x_max, y_max],\n","                'category_id': int(label),\n","                'area': float(area),\n","                'iscrowd': 0\n","            })\n","\n","        # Feed image + annotations into YOLOS processor\n","        encoding = self.processor(\n","            images=image,\n","            annotations={\n","                'image_id': idx,\n","                'annotations': annotations\n","            },\n","            return_tensors=\"pt\"\n","        )\n","\n","        # Remove batch dimension\n","        for k, v in encoding.items():\n","            if isinstance(v, torch.Tensor):\n","                encoding[k] = v.squeeze(0)  # remove batch dim only\n","            else:\n","                encoding[k] = v  # leave non-tensor items as-is\n","\n","        return encoding"],"metadata":{"id":"D52a7FnEuJRN","executionInfo":{"status":"ok","timestamp":1745060338193,"user_tz":-180,"elapsed":75,"user":{"displayName":"Nisan","userId":"17072699878303939405"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","# Initialize image processor\n","print(f\"Loading YOLOS image processor from {MODEL_CHECKPOINT}\")\n","processor = YolosImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n","\n","# Define data augmentations\n","\n","train_transform = A.Compose(\n","    [\n","        A.Resize(640, 640),\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.2),\n","        A.ShiftScaleRotate(\n","            shift_limit=0.05, scale_limit=0.1, rotate_limit=10, border_mode=0, p=0.5\n","        ),\n","    ],\n","    bbox_params=A.BboxParams(\n","        format='yolo',              #\n","        label_fields=['labels'],\n","        min_visibility=0.1,         # Discard boxes too small or barely visible\n","        clip=True,            # clips bboxes to [0, 1]\n","    )\n",")\n","\n","val_transform = A.Compose(\n","    [\n","        A.Resize(640, 640)  #\n","    ],\n","    bbox_params=A.BboxParams(\n","        format='yolo',\n","        label_fields=['labels'],\n","        clip=True,\n","    )\n",")\n","\n","\n","# Log augmentation pipeline to wandb\n","wandb.config.update({\n","    \"augmentations\": str(train_transform),\n","})\n","\n","# Create dataset\n","print(\"Creating datasets...\")\n","full_dataset = CustomObjectDetectionDataset(\n","    annotations,\n","    IMAGES_DIR,\n","    processor\n",")\n","\n","# If we haven't already split the dataset:\n","if not os.path.exists(f\"{OUTPUT_DIR}/dataset_splits.pkl\"):\n","\n","    # subsetting the data because it is too big\n","    subset_size = int(len(full_dataset) * 0.3)\n","\n","    # Create random subset indices\n","    indices = torch.randperm(len(full_dataset))[:subset_size]\n","\n","    # Create subset\n","    subset_dataset = torch.utils.data.Subset(full_dataset, indices)\n","\n","    # Split dataset\n","    train_size = int(0.7 * len(subset_dataset))\n","    remaining = len(subset_dataset) - train_size\n","    val_size = remaining // 2      # 15% of subset\n","    test_size = remaining - val_size  # 15% of subset\n","    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(subset_dataset, [train_size, val_size, test_size])\n","\n","    # Save splits using indices for reproducibility\n","    split_indices = {\n","        \"subset_indices\": indices,\n","        \"train_indices\": train_dataset.indices,\n","        \"val_indices\": val_dataset.indices,\n","        \"test_indices\": test_dataset.indices\n","    }\n","\n","    with open(f\"{OUTPUT_DIR}/dataset_splits.pkl\", \"wb\") as f:\n","        pickle.dump(split_indices, f)\n","\n","with open(f\"{OUTPUT_DIR}/dataset_splits.pkl\", \"rb\") as f:\n","    loaded_splits = pickle.load(f)\n","\n","#subset the data\n","subset_dataset = torch.utils.data.Subset(full_dataset, loaded_splits[\"subset_indices\"])\n","\n","# Recreate datasets using original dataset\n","train_dataset = torch.utils.data.Subset(subset_dataset, loaded_splits[\"train_indices\"])\n","val_dataset = torch.utils.data.Subset(subset_dataset, loaded_splits[\"val_indices\"])\n","test_dataset = torch.utils.data.Subset(subset_dataset, loaded_splits[\"test_indices\"])\n","\n","\n","# Apply transforms\n","train_dataset.dataset.transform = train_transform\n","val_dataset.dataset.transform = val_transform\n","test_dataset.dataset.transform = val_transform\n","\n","print(f\"Train dataset size: {len(train_dataset)}\")\n","print(f\"Validation dataset size: {len(val_dataset)}\")\n","print(f\"Test dataset size: {len(test_dataset)}\")\n","\n","\n","# Log data split info\n","wandb.config.update({\n","    \"train_size\": len(train_dataset),\n","    \"val_size\": len(val_dataset),\n","    \"train_val_ratio\": train_size / val_size if val_size > 0 else \"N/A\",\n","})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329,"referenced_widgets":["c4547897ae8a425083fd0bc10336ba7a","f8a9b96fbd804334a3cc7f5a6665d227","3f2928dbfa9b4d609d8318dba5dd90cd","4ecd5d1002754c3396d67b8f0eda033d","d6407f4e28d74d48aa002d3af82605b4","f6ab661add744f489f98863bb569b790","0e3c2fe4841e447db747d2d00cb47e5e","a7d70638f8d44e2e97f6eb8ea736a3a0","fa78a32731534fae8506819859523500","1882edceba3a45ee8653559d8250a6fc","6f797802337f4be09636af29b601e0b2"]},"id":"9SiURuxLwU6G","executionInfo":{"status":"ok","timestamp":1745060344545,"user_tz":-180,"elapsed":1413,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"a3cdde38-6353-40d9-c821-a0616a0adee5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading YOLOS image processor from hustvl/yolos-small\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/292 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4547897ae8a425083fd0bc10336ba7a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Creating datasets...\n","Train dataset size: 6892\n","Validation dataset size: 1477\n","Test dataset size: 1477\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n","  original_init(self, **validated_kwargs)\n"]}]},{"cell_type":"code","source":["from transformers import TrainerCallback\n","\n","def collate_fn(batch):\n","    batch_dict = {\n","        \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in batch])\n","    }\n","\n","    # For YOLOS, we need to keep labels as a list of label dictionaries\n","    if \"labels\" in batch[0]:\n","        batch_dict[\"labels\"] = [item[\"labels\"][0] for item in batch]\n","\n","    return batch_dict\n","\n","# Get model with updated config for your number of classes\n","print(f\"Loading YOLOS model from {MODEL_CHECKPOINT}\")\n","config = YolosConfig.from_pretrained(MODEL_CHECKPOINT, id2label=id2label, label2id=label2id)\n","model = YolosForObjectDetection.from_pretrained(MODEL_CHECKPOINT, config=config, ignore_mismatched_sizes=True)\n","\n","# Log model architecture summary to wandb\n","wandb.config.update({\n","    \"model_params\": sum(p.numel() for p in model.parameters()),\n","    \"trainable_params\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n","})\n","\n","# Enable gradient checkpointing to save memory\n","model.gradient_checkpointing_enable()\n","\n","# Create a custom callback to log losses to wandb and print progress\n","class WandbLoggingCallback(TrainerCallback):\n","    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n","        if metrics is not None:\n","            # Calculate epoch from global step\n","            epoch = state.epoch\n","\n","            # Print evaluation information\n","            print(f\"\\n=== Evaluation at Step {state.global_step} (Epoch {epoch:.2f}) ===\")\n","            for key, value in metrics.items():\n","                if key != \"epoch\":\n","                    print(f\"Eval {key}: {value:.5f}\")\n","\n","            # Log eval metrics to wandb\n","            wandb.log(\n","                {f\"eval/{k}\": v for k, v in metrics.items() if k != \"epoch\"},\n","                step=state.global_step\n","            )\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        # Log training metrics\n","        if logs is not None:\n","            # Print training information\n","            if \"loss\" in logs:\n","                print(f\"Step {state.global_step} (Epoch {logs.get('epoch', state.epoch):.2f}) - Training loss: {logs['loss']:.5f}\")\n","\n","            # Filter out eval metrics which are handled in on_evaluate\n","            train_logs = {k: v for k, v in logs.items() if not k.startswith(\"eval_\")}\n","            wandb.log(\n","                {f\"train/{k}\": v for k, v in train_logs.items() if k != \"epoch\"},\n","                step=state.global_step\n","            )\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    learning_rate=LEARNING_RATE,\n","    num_train_epochs=NUM_EPOCHS,\n","    warmup_ratio=WARMUP_RATIO,\n","    weight_decay=0.01,\n","    eval_strategy=\"steps\",\n","    eval_steps=EVAL_STEPS,\n","    save_strategy=\"steps\",\n","    save_steps=SAVE_STEPS,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    greater_is_better=False,\n","    push_to_hub=False,\n","    fp16=True,\n","    gradient_accumulation_steps=GRAD_ACCUMULATION_STEPS,\n","    save_total_limit=3,\n","    dataloader_num_workers=NUM_WORKERS,\n","    dataloader_drop_last=True,\n","    dataloader_pin_memory=True,\n","    report_to=\"wandb\",\n","    gradient_checkpointing=True,\n","    ddp_find_unused_parameters=False,\n","    logging_strategy=\"steps\",  # Log at the same frequency as evaluation\n","    logging_steps=EVAL_STEPS // 5,  # Log more frequently than evaluation for better tracking\n","    logging_first_step=True,  # Log the first step to get initial loss\n",")\n","\n","# Initialize Trainer with early stopping and wandb logging\n","print(\"Initializing the Trainer...\")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=collate_fn,\n","    callbacks=[\n","        EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE),\n","        WandbLoggingCallback(),  # Add custom wandb logging callback\n","    ],\n",")\n","\n","# Train the model\n","print(\"\\n\" + \"=\"*50)\n","print(\"Starting training...\")\n","print(f\"Number of epochs: {NUM_EPOCHS}\")\n","print(f\"Training batch size: {BATCH_SIZE}\")\n","print(f\"Evaluation steps: Every {EVAL_STEPS} steps\")\n","print(f\"Saving steps: Every {SAVE_STEPS} steps\")\n","print(f\"Early stopping patience: {EARLY_STOPPING_PATIENCE} evaluations\")\n","print(\"=\"*50 + \"\\n\")\n","\n","train_result = trainer.train()\n","\n","# Print training summary\n","print(\"\\n\" + \"=\"*50)\n","print(\"Training completed!\")\n","print(f\"Total steps: {trainer.state.global_step}\")\n","print(f\"Final training loss: {train_result.training_loss:.5f}\")\n","print(\"=\"*50 + \"\\n\")\n","\n","# Save the final model\n","final_model_path = os.path.join(OUTPUT_DIR, \"final_model\")\n","trainer.save_model(final_model_path)\n","print(f\"Model saved to {final_model_path}\")\n","\n","# Create a validation dataset subset for final evaluation\n","print(\"\\nPerforming final evaluation...\")\n","eval_subset_size = min(1000, len(val_dataset))\n","eval_subset_indices = torch.randperm(len(val_dataset))[:eval_subset_size]\n","eval_subset = torch.utils.data.Subset(val_dataset, eval_subset_indices)\n","\n","# Evaluate the model on the validation subset\n","eval_results = trainer.evaluate(eval_dataset=eval_subset)\n","print(\"\\n\" + \"=\"*50)\n","print(\"Final evaluation results:\")\n","for key, value in eval_results.items():\n","    print(f\"{key}: {value:.5f}\")\n","print(\"=\"*50 + \"\\n\")\n","\n","# Finish wandb run\n","print(\"Finishing wandb run...\")\n","wandb.finish()\n","print(\"Training complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Uqz_Yt75CQmF","executionInfo":{"status":"ok","timestamp":1745067380627,"user_tz":-180,"elapsed":6769709,"user":{"displayName":"Nisan","userId":"17072699878303939405"}},"outputId":"d970c0b5-715e-4e79-eb32-0a7ef88b40a6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading YOLOS model from hustvl/yolos-small\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of YolosForObjectDetection were not initialized from the model checkpoint at hustvl/yolos-small and are newly initialized because the shapes did not match:\n","- class_labels_classifier.layers.2.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([9]) in the model instantiated\n","- class_labels_classifier.layers.2.weight: found shape torch.Size([92, 384]) in the checkpoint and torch.Size([9, 384]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Initializing the Trainer...\n","\n","==================================================\n","Starting training...\n","Number of epochs: 20\n","Training batch size: 4\n","Evaluation steps: Every 200 steps\n","Saving steps: Every 2000 steps\n","Early stopping patience: 4 evaluations\n","==================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2140' max='2140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2140/2140 1:52:08, Epoch 19/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>1.627200</td>\n","      <td>1.695755</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.450900</td>\n","      <td>1.467428</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.375500</td>\n","      <td>1.396618</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.339400</td>\n","      <td>1.411289</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.310100</td>\n","      <td>1.359288</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>1.276200</td>\n","      <td>1.326345</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>1.230000</td>\n","      <td>1.264164</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>1.192900</td>\n","      <td>1.233741</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>1.188100</td>\n","      <td>1.215379</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.125500</td>\n","      <td>1.203504</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Step 1 (Epoch 0.01) - Training loss: 7.90780\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 40 (Epoch 0.37) - Training loss: 6.99180\n","Step 80 (Epoch 0.74) - Training loss: 3.35990\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 120 (Epoch 1.11) - Training loss: 1.92620\n","Step 160 (Epoch 1.48) - Training loss: 1.69750\n","Step 200 (Epoch 1.85) - Training loss: 1.62720\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 200 (Epoch 1.85) ===\n","Eval eval_loss: 1.69576\n","Eval eval_runtime: 152.79720\n","Eval eval_samples_per_second: 9.66600\n","Eval eval_steps_per_second: 2.42200\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 240 (Epoch 2.22) - Training loss: 1.58470\n","Step 280 (Epoch 2.59) - Training loss: 1.56280\n","Step 320 (Epoch 2.97) - Training loss: 1.50970\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 360 (Epoch 3.33) - Training loss: 1.48020\n","Step 400 (Epoch 3.71) - Training loss: 1.45090\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 400 (Epoch 3.71) ===\n","Eval eval_loss: 1.46743\n","Eval eval_runtime: 30.07320\n","Eval eval_samples_per_second: 49.11300\n","Eval eval_steps_per_second: 12.30300\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 440 (Epoch 4.07) - Training loss: 1.43990\n","Step 480 (Epoch 4.45) - Training loss: 1.45570\n","Step 520 (Epoch 4.82) - Training loss: 1.40400\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 560 (Epoch 5.19) - Training loss: 1.35700\n","Step 600 (Epoch 5.56) - Training loss: 1.37550\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 600 (Epoch 5.56) ===\n","Eval eval_loss: 1.39662\n","Eval eval_runtime: 29.98820\n","Eval eval_samples_per_second: 49.25300\n","Eval eval_steps_per_second: 12.33800\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 640 (Epoch 5.93) - Training loss: 1.36820\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 680 (Epoch 6.30) - Training loss: 1.36810\n","Step 720 (Epoch 6.67) - Training loss: 1.36010\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 760 (Epoch 7.04) - Training loss: 1.32850\n","Step 800 (Epoch 7.41) - Training loss: 1.33940\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 800 (Epoch 7.41) ===\n","Eval eval_loss: 1.41129\n","Eval eval_runtime: 30.09740\n","Eval eval_samples_per_second: 49.07400\n","Eval eval_steps_per_second: 12.29300\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 840 (Epoch 7.78) - Training loss: 1.35120\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 880 (Epoch 8.15) - Training loss: 1.29820\n","Step 920 (Epoch 8.52) - Training loss: 1.32140\n","Step 960 (Epoch 8.89) - Training loss: 1.33690\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1000 (Epoch 9.26) - Training loss: 1.31010\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 1000 (Epoch 9.26) ===\n","Eval eval_loss: 1.35929\n","Eval eval_runtime: 29.93420\n","Eval eval_samples_per_second: 49.34100\n","Eval eval_steps_per_second: 12.36000\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 1001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 1001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1040 (Epoch 9.63) - Training loss: 1.32260\n","Step 1080 (Epoch 10.00) - Training loss: 1.32250\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1120 (Epoch 10.37) - Training loss: 1.28560\n","Step 1160 (Epoch 10.74) - Training loss: 1.28850\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1200 (Epoch 11.11) - Training loss: 1.27620\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 1200 (Epoch 11.11) ===\n","Eval eval_loss: 1.32635\n","Eval eval_runtime: 30.09640\n","Eval eval_samples_per_second: 49.07600\n","Eval eval_steps_per_second: 12.29400\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 1201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 1201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1240 (Epoch 11.48) - Training loss: 1.27250\n","Step 1280 (Epoch 11.85) - Training loss: 1.24500\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1320 (Epoch 12.22) - Training loss: 1.23780\n","Step 1360 (Epoch 12.59) - Training loss: 1.24950\n","Step 1400 (Epoch 12.97) - Training loss: 1.23000\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 1400 (Epoch 12.97) ===\n","Eval eval_loss: 1.26416\n","Eval eval_runtime: 30.08260\n","Eval eval_samples_per_second: 49.09800\n","Eval eval_steps_per_second: 12.29900\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 1401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 1401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1440 (Epoch 13.33) - Training loss: 1.22420\n","Step 1480 (Epoch 13.71) - Training loss: 1.21450\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1520 (Epoch 14.07) - Training loss: 1.19870\n","Step 1560 (Epoch 14.45) - Training loss: 1.21940\n","Step 1600 (Epoch 14.82) - Training loss: 1.19290\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 1600 (Epoch 14.82) ===\n","Eval eval_loss: 1.23374\n","Eval eval_runtime: 30.13070\n","Eval eval_samples_per_second: 49.02000\n","Eval eval_steps_per_second: 12.28000\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 1601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 1601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1640 (Epoch 15.19) - Training loss: 1.18460\n","Step 1680 (Epoch 15.56) - Training loss: 1.19520\n","Step 1720 (Epoch 15.93) - Training loss: 1.18550\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1760 (Epoch 16.30) - Training loss: 1.17080\n","Step 1800 (Epoch 16.67) - Training loss: 1.18810\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 1800 (Epoch 16.67) ===\n","Eval eval_loss: 1.21538\n","Eval eval_runtime: 30.07320\n","Eval eval_samples_per_second: 49.11400\n","Eval eval_steps_per_second: 12.30300\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1800 that is less than the current step 1801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1800 that is less than the current step 1801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1840 (Epoch 17.04) - Training loss: 1.13850\n","Step 1880 (Epoch 17.41) - Training loss: 1.15940\n","Step 1920 (Epoch 17.78) - Training loss: 1.15350\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 1960 (Epoch 18.15) - Training loss: 1.13710\n","Step 2000 (Epoch 18.52) - Training loss: 1.12550\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 2000 (Epoch 18.52) ===\n","Eval eval_loss: 1.20350\n","Eval eval_runtime: 30.03810\n","Eval eval_samples_per_second: 49.17100\n","Eval eval_steps_per_second: 12.31800\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2000 that is less than the current step 2001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2000 that is less than the current step 2001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"]},{"output_type":"stream","name":"stdout","text":["Step 2040 (Epoch 18.89) - Training loss: 1.13990\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"stream","name":"stdout","text":["Step 2080 (Epoch 19.26) - Training loss: 1.12140\n","Step 2120 (Epoch 19.63) - Training loss: 1.12360\n","\n","==================================================\n","Training completed!\n","Total steps: 2140\n","Final training loss: 1.45783\n","==================================================\n","\n","Model saved to yolos_finetuned/final_model\n","\n","Performing final evaluation...\n"]},{"output_type":"stream","name":"stderr","text":["The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/250 00:19]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","=== Evaluation at Step 2140 (Epoch 19.82) ===\n","Eval eval_loss: 1.21375\n","Eval eval_runtime: 21.00050\n","Eval eval_samples_per_second: 47.61800\n","Eval eval_steps_per_second: 11.90400\n","\n","==================================================\n","Final evaluation results:\n","eval_loss: 1.21375\n","eval_runtime: 21.00050\n","eval_samples_per_second: 47.61800\n","eval_steps_per_second: 11.90400\n","epoch: 19.81718\n","==================================================\n","\n","Finishing wandb run...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▄▃▃▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁██████████</td></tr><tr><td>eval/steps_per_second</td><td>▁██████████</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▄▄▅▄▃▄▄▂▄▄▄▄▅▅▄▄▆▂▂▃█▄▃▂▃▂▂▂▄▄▅▃▅▃▃▃▁▃▃▅</td></tr><tr><td>train/learning_rate</td><td>▁▃▆███▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.21375</td></tr><tr><td>eval/runtime</td><td>21.0005</td></tr><tr><td>eval/samples_per_second</td><td>47.618</td></tr><tr><td>eval/steps_per_second</td><td>11.904</td></tr><tr><td>total_flos</td><td>7.365561136055989e+19</td></tr><tr><td>train/epoch</td><td>19.81718</td></tr><tr><td>train/global_step</td><td>2140</td></tr><tr><td>train/grad_norm</td><td>32.69291</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1236</td></tr><tr><td>train/total_flos</td><td>7.365561136055989e+19</td></tr><tr><td>train/train_loss</td><td>1.45783</td></tr><tr><td>train/train_runtime</td><td>6736.1482</td></tr><tr><td>train/train_samples_per_second</td><td>20.463</td></tr><tr><td>train/train_steps_per_second</td><td>0.318</td></tr><tr><td>train_loss</td><td>1.45783</td></tr><tr><td>train_runtime</td><td>6736.1482</td></tr><tr><td>train_samples_per_second</td><td>20.463</td></tr><tr><td>train_steps_per_second</td><td>0.318</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolos-small-20250419-105820</strong> at: <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/z6szt6dd' target=\"_blank\">https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer/runs/z6szt6dd</a><br> View project at: <a href='https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer' target=\"_blank\">https://wandb.ai/yildizz-nisan-middle-east-technical-university/object_detection_transformer</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250419_105838-z6szt6dd/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tried to log to step 2140 that is less than the current step 2141. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tried to log to step 2140 that is less than the current step 2141. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6oYKWmZkI9Wi"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOKsQ0FV5tMsTzlTJ5oh2r3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c4547897ae8a425083fd0bc10336ba7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8a9b96fbd804334a3cc7f5a6665d227","IPY_MODEL_3f2928dbfa9b4d609d8318dba5dd90cd","IPY_MODEL_4ecd5d1002754c3396d67b8f0eda033d"],"layout":"IPY_MODEL_d6407f4e28d74d48aa002d3af82605b4"}},"f8a9b96fbd804334a3cc7f5a6665d227":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6ab661add744f489f98863bb569b790","placeholder":"​","style":"IPY_MODEL_0e3c2fe4841e447db747d2d00cb47e5e","value":"preprocessor_config.json: 100%"}},"3f2928dbfa9b4d609d8318dba5dd90cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7d70638f8d44e2e97f6eb8ea736a3a0","max":292,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa78a32731534fae8506819859523500","value":292}},"4ecd5d1002754c3396d67b8f0eda033d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1882edceba3a45ee8653559d8250a6fc","placeholder":"​","style":"IPY_MODEL_6f797802337f4be09636af29b601e0b2","value":" 292/292 [00:00&lt;00:00, 34.8kB/s]"}},"d6407f4e28d74d48aa002d3af82605b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6ab661add744f489f98863bb569b790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e3c2fe4841e447db747d2d00cb47e5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7d70638f8d44e2e97f6eb8ea736a3a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa78a32731534fae8506819859523500":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1882edceba3a45ee8653559d8250a6fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f797802337f4be09636af29b601e0b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}